# Sohu-Biendata-Baseline-Test
大赛背景介绍
随着信息技术的不断发展，千人千面的信息推荐方式给亿万网民的阅读带来了便利，但同时营销、低俗、标题党等低质量新闻的掺杂也给用户带来了不同程度上的困扰。
给用户提供更好的阅读体验，一直是搜狐新闻追求的目标。新闻资源是一切服务的基石，只有在高质量新闻资源的基础上，才可能构建用户体验的巴别塔。
因此，准确识别低质量的新闻资源，是提高新闻资源质量的重要的环节，也是新闻资讯领域共待解决的重要课题。

任务描述
参赛队伍利用主办方给定的数据集来训练模型，训练数据分为标注数据（数据集规模为5万条新闻和35万张新闻配图，标注为有营销意图的新闻、文本片段和配图），和未标注数据（数据规模为20万条新闻和100万张新闻配图）。比赛要求在给定新的新闻内容集合和配图集合之后（数据集规模为1万条新闻和7万张新闻配图），参赛队伍能识别出有营销意图的新闻、文本片段和配图。

处理策略
由于标注内容有0，1，2。0表示完全无营销意图，1表示部分有营销意图，且需标出部分有营销意图对句子，2表示有50%以上句子有营销意图。
因此本代码从两个方面对文本进行处理，（1）长文本处理，也就是整段进行处理；（2）短文本处理，以句子为单位进行处理。最后将长文本和短文本结果进行融合（融合部分代码未展示）。
长短文本的处理策略比较简单，处理流程如下：
（1）	数据预处理，对文本进行分词（thulac），停用词需自己导入；
（2）	利用卡方统计进行特征选择，选择卡方分数最高的5000个特征词；
（3）	通过TF-IDF方法对分词结果特征计算，并转换到词向量；
（4）	将词向量作为特征进行逻辑回归，计算文本营销意图的可能性(probability)。最后将probability二值化获得结果。
TF-IDF（term frequency–inverse document frequency）是一种用于资讯检索的常用加权技术。TF-IDF是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。字词的重要性随着它在文件中出现的次数成正比增加，但同时会随着它在语料库中出现的频率成反比下降。
